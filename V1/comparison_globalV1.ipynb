{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import h5py\n",
    "import netCDF4\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions and variables\n",
    "def Ne_convert(e: float,P: float,T: float) -> float:\n",
    "    \"\"\"Convert electron concentration to density\n",
    "\n",
    "    Args:\n",
    "        e (float): Mixing ration\n",
    "        P (float): Pressure\n",
    "        T (float): Temperature\n",
    "\n",
    "    Returns:\n",
    "        float: Electron density\n",
    "    \"\"\"\n",
    "    return e*P/(k*T)\n",
    "\n",
    "def z(p):\n",
    "    \"\"\"Convert pressure to altitude\n",
    "\n",
    "    Args:\n",
    "        p (float): pressure (in hPa)\n",
    "\n",
    "    Returns:\n",
    "        float: altitude (in km)\n",
    "    \"\"\"\n",
    "    return - 7 * np.log(p/1013.25)\n",
    "\n",
    "def convert_utime(start_time: float, end_time: float):\n",
    "    \"\"\"Convert numpy.float65 to datetime.datetime \n",
    "\n",
    "    Args:\n",
    "        start_time (float): Start time of the measured data\n",
    "        end_time (float): End time of the measured data\n",
    "\n",
    "    Returns:\n",
    "        datetime,datetime: Date converted to datetime\n",
    "    \"\"\"\n",
    "    start_time2, end_time2 = [], []\n",
    "    if len(start_time) == len(end_time):\n",
    "        for i in range(len(start_time)):\n",
    "            start_time2.append(datetime.fromtimestamp(data['utime'][0][i]))\n",
    "            end_time2.append(datetime.fromtimestamp(data['utime'][1][i]))\n",
    "        return np.array(start_time2), np.array(end_time2)\n",
    "    \n",
    "def get_nrec(metadata,data):\n",
    "    \"\"\"Get nrec value from searching in metadata\n",
    "\n",
    "    Args:\n",
    "        metadata ([[String]]): Metadata array\n",
    "        data ([[String]]): Data array\n",
    "    Returns:\n",
    "        int: number of height measurements \n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for array in metadata:\n",
    "        if array[0].strip() == b'nrec':\n",
    "            return(data[i][0])\n",
    "        i += 1\n",
    "\n",
    "k = 1.38*10**(-23) # J/K\n",
    "lim = 0.3\n",
    "time_save = np.linspace(0,24,49)\n",
    "H_list = np.linspace(80,132,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 folders found.\n",
      "Folder: ../../DataSorted/2004-03-31, Global model correlation: 36.62, Global measure correlation: 38.37, index: 1/57\n",
      "Folder: ../../DataSorted/2004-12-08, Global model correlation: 15.22, Global measure correlation: 12.5, index: 2/57\n",
      "Folder: ../../DataSorted/2004-12-01, Global model correlation: 20.62, Global measure correlation: 20.0, index: 3/57\n",
      "Folder: ../../DataSorted/2004-12-06, Global model correlation: 18.59, Global measure correlation: 20.15, index: 4/57\n",
      "Folder: ../../DataSorted/2004-01-21, Global model correlation: 30.88, Global measure correlation: 30.88, index: 5/57\n",
      "Folder: ../../DataSorted/2004-06-09, Global model correlation: 15.62, Global measure correlation: 15.05, index: 6/57\n",
      "Folder: ../../DataSorted/2004-05-29, Global model correlation: 14.45, Global measure correlation: 14.97, index: 7/57\n",
      "Folder: ../../DataSorted/2004-06-07, Global model correlation: 21.67, Global measure correlation: 19.53, index: 8/57\n",
      "Folder: ../../DataSorted/2004-05-20, Global model correlation: 26.93, Global measure correlation: 25.1, index: 9/57\n",
      "Folder: ../../DataSorted/2004-05-27, Global model correlation: 18.85, Global measure correlation: 19.95, index: 10/57\n",
      "Folder: ../../DataSorted/2004-05-18, Global model correlation: 22.13, Global measure correlation: 20.05, index: 11/57\n",
      "Folder: ../../DataSorted/2004-09-14, Global model correlation: 27.25, Global measure correlation: 30.75, index: 12/57\n",
      "Folder: ../../DataSorted/2004-12-07, Global model correlation: 16.46, Global measure correlation: 14.9, index: 13/57\n",
      "Folder: ../../DataSorted/2004-09-13, Global model correlation: 28.19, Global measure correlation: 28.98, index: 14/57\n",
      "Folder: ../../DataSorted/2004-12-09, Global model correlation: 13.19, Global measure correlation: 11.94, index: 15/57\n",
      "Folder: ../../DataSorted/2004-11-11, Global model correlation: 24.46, Global measure correlation: 27.39, index: 16/57\n",
      "Folder: ../../DataSorted/2004-06-01, Global model correlation: 22.67, Global measure correlation: 21.65, index: 17/57\n",
      "Folder: ../../DataSorted/2004-05-26, Global model correlation: 16.29, Global measure correlation: 15.95, index: 18/57\n",
      "Folder: ../../DataSorted/2004-05-19, Global model correlation: 24.66, Global measure correlation: 23.47, index: 19/57\n",
      "Folder: ../../DataSorted/2004-06-06, Global model correlation: 19.59, Global measure correlation: 18.5, index: 20/57\n",
      "Folder: ../../DataSorted/2004-05-28, Global model correlation: 18.63, Global measure correlation: 18.28, index: 21/57\n",
      "Folder: ../../DataSorted/2004-06-08, Global model correlation: 14.15, Global measure correlation: 14.03, index: 22/57\n",
      "Folder: ../../DataSorted/2004-11-01-SOL, Global model correlation: 5.8, Global measure correlation: 4.91, index: 23/57\n",
      "Folder: ../../DataSorted/2004-06-12, Global model correlation: 14.82, Global measure correlation: 14.7, index: 24/57\n",
      "Folder: ../../DataSorted/2004-06-24, Global model correlation: 29.59, Global measure correlation: 26.83, index: 25/57\n",
      "Folder: ../../DataSorted/2004-06-23, Global model correlation: 31.9, Global measure correlation: 27.6, index: 26/57\n",
      "Folder: ../../DataSorted/2004-11-10-GEO, Global model correlation: 24.55, Global measure correlation: 27.58, index: 27/57\n",
      "Folder: ../../DataSorted/2004-06-22, Global model correlation: 12.76, Global measure correlation: 12.5, index: 28/57\n",
      "Folder: ../../DataSorted/2004-06-25, Global model correlation: 19.87, Global measure correlation: 16.62, index: 29/57\n",
      "Folder: ../../DataSorted/2004-06-13, Global model correlation: 14.02, Global measure correlation: 13.47, index: 30/57\n",
      "Folder: ../../DataSorted/2004-03-12, Global model correlation: 44.79, Global measure correlation: 51.04, index: 31/57\n",
      "Folder: ../../DataSorted/2004-11-07-SOL, Global model correlation: 12.1, Global measure correlation: 13.28, index: 32/57\n",
      "Folder: ../../DataSorted/2004-08-30, Global model correlation: 38.83, Global measure correlation: 33.48, index: 33/57\n",
      "Folder: ../../DataSorted/2004-01-22-GEO, Global model correlation: 23.33, Global measure correlation: 22.5, index: 34/57\n",
      "Folder: ../../DataSorted/2004-05-24, Global model correlation: 18.26, Global measure correlation: 18.87, index: 35/57\n",
      "Folder: ../../DataSorted/2004-06-03, Global model correlation: 21.16, Global measure correlation: 19.95, index: 36/57\n",
      "Folder: ../../DataSorted/2004-06-04, Global model correlation: 20.56, Global measure correlation: 17.74, index: 37/57\n",
      "Folder: ../../DataSorted/2004-05-23, Global model correlation: 22.62, Global measure correlation: 23.25, index: 38/57\n",
      "Folder: ../../DataSorted/2004-04-03-GEO, Global model correlation: 28.12, Global measure correlation: 30.69, index: 39/57\n",
      "Folder: ../../DataSorted/2004-11-13, Global model correlation: 11.66, Global measure correlation: 13.19, index: 40/57\n",
      "Folder: ../../DataSorted/2004-05-22, Global model correlation: 20.98, Global measure correlation: 19.75, index: 41/57\n",
      "Folder: ../../DataSorted/2004-06-05, Global model correlation: 13.31, Global measure correlation: 12.5, index: 42/57\n",
      "Folder: ../../DataSorted/2004-06-02, Global model correlation: 23.46, Global measure correlation: 23.02, index: 43/57\n",
      "Folder: ../../DataSorted/2004-05-25, Global model correlation: 17.38, Global measure correlation: 17.57, index: 44/57\n",
      "Folder: ../../DataSorted/2004-11-09-GEO, Global model correlation: 23.94, Global measure correlation: 27.02, index: 45/57\n",
      "Folder: ../../DataSorted/2004-11-12, Global model correlation: 17.34, Global measure correlation: 21.93, index: 46/57\n",
      "Folder: ../../DataSorted/2004-11-06, Global model correlation: 15.87, Global measure correlation: 16.0, index: 47/57\n",
      "Folder: ../../DataSorted/2004-06-11, Global model correlation: 18.51, Global measure correlation: 17.12, index: 48/57\n",
      "Folder: ../../DataSorted/2004-05-31, Global model correlation: 16.42, Global measure correlation: 16.05, index: 49/57\n",
      "Folder: ../../DataSorted/2004-06-20, Global model correlation: 18.37, Global measure correlation: 16.09, index: 50/57\n",
      "Folder: ../../DataSorted/2004-06-19, Global model correlation: 21.93, Global measure correlation: 18.87, index: 51/57\n",
      "Folder: ../../DataSorted/2004-06-21, Global model correlation: 25.5, Global measure correlation: 20.75, index: 52/57\n",
      "Folder: ../../DataSorted/2004-05-30, Global model correlation: 16.07, Global measure correlation: 16.66, index: 53/57\n",
      "Folder: ../../DataSorted/2004-06-10, Global model correlation: 14.55, Global measure correlation: 13.57, index: 54/57\n",
      "Folder: ../../DataSorted/2004-03-29, Global model correlation: 25.31, Global measure correlation: 29.06, index: 55/57\n",
      "Folder: ../../DataSorted/2004-04-01, Global model correlation: 1.81, Global measure correlation: 1.81, index: 56/57\n",
      "Folder: ../../DataSorted/2004-04-06, Global model correlation: 23.43, Global measure correlation: 25.78, index: 57/57\n"
     ]
    }
   ],
   "source": [
    "data_folder_path = '../../DataSorted/*'\n",
    "data_folders = glob(data_folder_path)\n",
    "print(len(data_folders), 'folders found.')\n",
    "\n",
    "npy_files_path = '../../Results/'\n",
    "npy_files = glob(npy_files_path + '*.npy')\n",
    "\n",
    "correlation_model_path = 'correlation_model.npy'\n",
    "correlation_measure_path = 'correlation_measure.npy'\n",
    "density_path = 'density_difference.npy'\n",
    "frequency_path = 'frequency.npy'\n",
    "\n",
    "for npy_file in npy_files:\n",
    "    if os.path.isfile(npy_file):\n",
    "        os.remove(npy_file)\n",
    "        print(f'{npy_file} has been deleted successfully.')\n",
    "\n",
    "index = 1\n",
    "\n",
    "for folder in data_folders:\n",
    "    WACCM_path = folder + '/*.nc'\n",
    "    EISCAT_path = folder + '/EISCAT*.hdf5'\n",
    "\n",
    "    WACCM_files = []\n",
    "    EISCAT_files = []\n",
    "\n",
    "    if len(glob(WACCM_path)) == 1:\n",
    "        WACCM_files = [netCDF4.Dataset(glob(WACCM_path)[0])]\n",
    "    elif len(glob(WACCM_path)) > 1:\n",
    "        for file in glob(WACCM_path):\n",
    "            WACCM_files.append(netCDF4.Dataset(glob(file)[0]))\n",
    "\n",
    "    if len(glob(EISCAT_path)) == 1:\n",
    "        EISCAT_files = [h5py.File(glob(EISCAT_path)[0])]\n",
    "    elif len(glob(EISCAT_path)) > 1:\n",
    "        for file in glob(EISCAT_path):\n",
    "            EISCAT_files.append(h5py.File(glob(file)[0]))\n",
    "\n",
    "    WACCM_file = WACCM_files[0]\n",
    "    EISCAT_file = EISCAT_files[0]\n",
    "\n",
    "    lat = WACCM_file['instr_lat'] \n",
    "    lon = WACCM_file['instr_lon'] \n",
    "    num = WACCM_file['instr_num'] \n",
    "    date = WACCM_file['obs_date'] \n",
    "    time = WACCM_file['obs_time']\n",
    "    lev = WACCM_file['lev']\n",
    "    e = WACCM_file['e']\n",
    "    T = WACCM_file['T'] \n",
    "\n",
    "    mask_tromso = (lat[:] > 69.5) & (lat[:] < 69.7)\n",
    "    mask_svalbard = (lat[:] > 78.8) & (lat[:] < 79.0)\n",
    "\n",
    "\n",
    "    lev_mask = lev[:] < 0.01\n",
    "    P = lev[lev_mask]\n",
    "    H = z(P)\n",
    "    NeWACCM = []\n",
    "\n",
    "    for array in e[mask_svalbard]:\n",
    "        NeWACCM.append(array[lev_mask])\n",
    "\n",
    "    NeWACCM = np.array(NeWACCM)\n",
    "    hours = time[mask_svalbard]/3600\n",
    "\n",
    "    mask_hours = [hours[i] > hours[i+1] for i in range(len(hours)-1)]\n",
    "    indices = [i+1 for i, value in enumerate(mask_hours) if value]\n",
    "\n",
    "    for indice in indices:\n",
    "        hours[indice:] = hours[indice:] + 24\n",
    "\n",
    "    data = EISCAT_file['data']\n",
    "    metadata = EISCAT_file['metadata'] \n",
    "\n",
    "    nrec = get_nrec(metadata['par0d'][:],data['par0d'][:])  \n",
    "    h = data['par2d'][0]\n",
    "    Ne = data['par2d'][2]\n",
    "    Ti = data['par2d'][3] \n",
    "    Te = data['par2d'][4] \n",
    "    ve = data['par2d'][6] \n",
    "    Time = np.repeat(data['utime'][0], nrec)\n",
    "\n",
    "    start_date, end_date = convert_utime(data['utime'][0],data['utime'][1]) \n",
    "    mask = h <= 150000 \n",
    "    Timebis = np.repeat(start_date, nrec) \n",
    "    Time_hours_minutes = np.array([float(t.strftime('%H.%M')) for t in Timebis]) \n",
    "    Date = start_date[0].strftime('%Y-%m-%d')\n",
    "    date_EISCAT = start_date[0].strftime('%Y%m%d')\n",
    "\n",
    "    h = h[mask]/1000\n",
    "    Ne = Ne[mask]\n",
    "    Ti = Ti[mask]\n",
    "    Te = Te[mask]\n",
    "    Te = Ti*Te\n",
    "    ve = ve[mask]\n",
    "    Time = Time[mask]\n",
    "    Timebis = Timebis[mask]\n",
    "    Time_hours_minutes = Time_hours_minutes[mask]\n",
    "\n",
    "    for i in range(len(Time_hours_minutes)-1):\n",
    "        if Time_hours_minutes[i+1] < Time_hours_minutes[i]:\n",
    "            Time_hours_minutes[i+1] = Time_hours_minutes[i+1] + 24\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for i in range(len(Time_hours_minutes)):\n",
    "        fractional_part, integer_part = math.modf(float(Time_hours_minutes[i]))\n",
    "        Time_hours_minutes[i] = integer_part + int(fractional_part/0.6*100)/100\n",
    "        if int(date_EISCAT[-4:-2])!= int(str(date[0])[-4:-2]):\n",
    "            if int(str(date[0])[-4:-2]) in [1,3,5,7,8,10,12]:\n",
    "                Time_hours_minutes[i] += 24 * (int(date_EISCAT[-2:]) + int(str(date[0])[-2:]) - 31)\n",
    "            elif int(str(date[0])[-4:-2]) == 2:\n",
    "                Time_hours_minutes[i] += 24 * (int(date_EISCAT[-2:]) + int(str(date[0])[-2:]) - 38)\n",
    "            else:\n",
    "                Time_hours_minutes[i] += 24 * (int(date_EISCAT[-2:]) + int(str(date[0])[-2:]) - 30)\n",
    "        elif int(date_EISCAT) != int(date[0]):\n",
    "            Time_hours_minutes[i] += 24 * (int(date_EISCAT) - int(date[0]))\n",
    "    \n",
    "    n = len(Time_hours_minutes)\n",
    "\n",
    "    newHours = np.array([])\n",
    "\n",
    "    Ne_diff_WACCM = np.array([])\n",
    "    Ne_diff_EISCAT = np.array([])\n",
    "    H_diff_WACCM = np.array([])\n",
    "    H_diff_EISCAT = np.array([])\n",
    "    time_diff_WACCM = np.array([])\n",
    "    time_diff_EISCAT = np.array([])\n",
    "\n",
    "    i = 0\n",
    "    while hours[i] < max(Time_hours_minutes) and i < len(hours) - 1:\n",
    "        if hours[i] > min(Time_hours_minutes):\n",
    "            Ne_diff_WACCM = np.concatenate((Ne_diff_WACCM, Ne_convert(NeWACCM[i],P*100,T[i][lev_mask])))\n",
    "            H_diff_WACCM = np.concatenate((H_diff_WACCM, H))\n",
    "            time_diff_WACCM = np.concatenate((time_diff_WACCM, [hours[i]]))\n",
    "        i += 1\n",
    "    \n",
    "    newHours = hours[:i]\n",
    "\n",
    "    i = 0\n",
    "    while newHours[i] < min(Time_hours_minutes):\n",
    "        i += 1\n",
    "\n",
    "    newHours = newHours[i:]\n",
    "\n",
    "    i = 0\n",
    "    for i in range(len(newHours)):\n",
    "        t_mask = (Time_hours_minutes > newHours[i]) & (Time_hours_minutes < newHours[i] + 0.5)\n",
    "        if sum(t_mask) != 0:\n",
    "            time1 = Time_hours_minutes[t_mask]\n",
    "            Ne1 = Ne[t_mask]\n",
    "            h1 = h[t_mask]\n",
    "            for j in range(len(H)):\n",
    "                h_mask = ((h1 - H[j])**2 < 10)\n",
    "                if sum(h_mask != 0):\n",
    "                    Ne2 = np.mean(Ne1[h_mask])\n",
    "                    Ne_diff_EISCAT = np.concatenate((Ne_diff_EISCAT, np.array([Ne2])))\n",
    "                    H_diff_EISCAT = np.concatenate((H_diff_EISCAT, [H[j]]))\n",
    "                    time_diff_EISCAT = np.concatenate((time_diff_EISCAT, [newHours[i]]))\n",
    "                else:\n",
    "                    Ne_diff_EISCAT = np.concatenate((Ne_diff_EISCAT, np.array([0])))\n",
    "                    H_diff_EISCAT = np.concatenate((H_diff_EISCAT, [H[j]]))\n",
    "                    time_diff_EISCAT = np.concatenate((time_diff_EISCAT, [newHours[i]]))\n",
    "        else:\n",
    "            Ne_diff_EISCAT = np.concatenate((Ne_diff_EISCAT, np.repeat([0], len(H))))\n",
    "            H_diff_EISCAT = np.concatenate((H_diff_EISCAT, H))\n",
    "            time_diff_EISCAT = np.concatenate((time_diff_EISCAT, np.repeat(hours[i], len(H))))\n",
    "    \n",
    "    mask = Ne_diff_EISCAT != 0\n",
    "    time_diff = time_diff_EISCAT\n",
    "    H_diff = H_diff_EISCAT\n",
    "\n",
    "    corr_factor_model = np.zeros(len(np.unique(H_diff))*len(time_diff_WACCM))\n",
    "    corr_factor_model[mask] = (Ne_diff_EISCAT[mask] - Ne_diff_WACCM[mask])/Ne_diff_WACCM[mask]\n",
    "\n",
    "    corr_factor_measure = np.zeros(len(np.unique(H_diff))*len(time_diff_WACCM))\n",
    "    corr_factor_measure[mask] = (Ne_diff_EISCAT[mask] - Ne_diff_WACCM[mask])/Ne_diff_EISCAT[mask]\n",
    "\n",
    "\n",
    "    diff_density = np.abs(Ne_diff_WACCM - Ne_diff_EISCAT)\n",
    "    diff_density[~mask] = 0\n",
    "\n",
    "    if min(time_diff) > 24:\n",
    "        time_diff = time_diff - 24 * (min(time_diff) // 24)\n",
    "\n",
    "    mask24 = time_diff <= 24\n",
    "\n",
    "    time_diff = time_diff[mask24]\n",
    "    H_diff = H_diff[mask24]\n",
    "    corr_factor_model = corr_factor_model[mask24]\n",
    "    corr_factor_measure = corr_factor_measure[mask24]\n",
    "    Ne_diff = np.abs(Ne_diff_WACCM - Ne_diff_EISCAT)[mask24]\n",
    "\n",
    "\n",
    "    good_mask_model = np.abs(corr_factor_model) < lim\n",
    "    good_mask_measure = np.abs(corr_factor_measure) < lim\n",
    "    global_corr_model = sum(good_mask_model)/len(Ne_diff_WACCM)*100\n",
    "    global_corr_measure = sum(good_mask_measure)/len(Ne_diff_WACCM)*100\n",
    "\n",
    "    Ne_list = []\n",
    "\n",
    "    for h in H_list:\n",
    "        h_mask = np.abs(H_diff - h) <= 2\n",
    "        Ne_diff1 = Ne_diff[h_mask]\n",
    "        for time_incr in time_save:\n",
    "            t_mask = np.abs(time_diff[h_mask] - time_incr) < 0.25\n",
    "            if sum(t_mask) == 0:\n",
    "                Ne_list.append(0)\n",
    "            else:\n",
    "                Ne_diff2 = int(np.mean(Ne_diff1[t_mask]))\n",
    "                Ne_list.append(Ne_diff2)\n",
    "\n",
    "    Ne_array = np.array(Ne_list)\n",
    "\n",
    "    corr_model_list = []\n",
    "    corr_measure_list = []\n",
    "\n",
    "    for h in H_list:\n",
    "        h_mask = np.abs(H_diff - h) <= 2\n",
    "        corr1_model = corr_factor_model[h_mask]\n",
    "        corr1_measure = corr_factor_measure[h_mask]\n",
    "        for time_incr in time_save:\n",
    "            t_mask = np.abs(time_diff[h_mask] - time_incr) < 0.25\n",
    "            if sum(t_mask) == 0:\n",
    "                corr_model_list.append(0)\n",
    "                corr_measure_list.append(0)\n",
    "            else:\n",
    "                corr2_model = np.mean(corr1_model[t_mask])\n",
    "                corr2_measure = np.mean(corr1_measure[t_mask])\n",
    "                corr_model_list.append(corr2_model)\n",
    "                corr_measure_list.append(corr2_measure)\n",
    "\n",
    "    corr_model_array = np.array(corr_model_list)\n",
    "    corr_measure_array = np.array(corr_measure_list)\n",
    "    mask_corr = corr_model_array == 0\n",
    "    Ne_array[mask_corr] = 0\n",
    "\n",
    "    try:\n",
    "        loaded_density = np.load(npy_files_path + 'density_global' + '.npy')\n",
    "    except FileNotFoundError:\n",
    "        loaded_density = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "\n",
    "    Ne_save = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "    Ne_save = loaded_density + Ne_array\n",
    "    np.save(npy_files_path + 'density_global' + '.npy', Ne_save)\n",
    "\n",
    "    try:\n",
    "        loaded_correlation_model = np.load(npy_files_path + 'correlation_model_global' + '.npy')\n",
    "    except FileNotFoundError:\n",
    "        loaded_correlation_model = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "\n",
    "    corr_model_save = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "    corr_model_save = loaded_correlation_model + corr_model_array\n",
    "    np.save(npy_files_path + 'correlation_model_global' + '.npy', corr_model_save)\n",
    "\n",
    "    try:\n",
    "        loaded_correlation_measure = np.load(npy_files_path + 'correlation_measure_global' + '.npy')\n",
    "    except FileNotFoundError:\n",
    "        loaded_correlation_measure = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "\n",
    "    corr_measure_save = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "    corr_measure_save = loaded_correlation_measure + corr_measure_array\n",
    "    np.save(npy_files_path + 'correlation_measure_global' + '.npy', corr_measure_save)\n",
    "\n",
    "    try:\n",
    "        loaded_frequency = np.load(npy_files_path + 'frequency_global' + '.npy')\n",
    "    except FileNotFoundError:\n",
    "        loaded_frequency = np.ones(len(time_save)*len(np.unique(H_list)) + 1)\n",
    "\n",
    "    mask = np.array(Ne_array) != 0\n",
    "\n",
    "    freq_save = np.zeros(len(time_save)*len(np.unique(H_list)) + 1)\n",
    "    freq_save[1:][mask] = 1\n",
    "    freq_save += loaded_frequency\n",
    "    freq_save[0] += 1\n",
    "    np.save(npy_files_path + 'frequency_global' + '.npy', freq_save)\n",
    "\n",
    "    if folder[-4:] == '-GEO':\n",
    "        try:\n",
    "            loaded_density = np.load(npy_files_path + 'density_geomagnetic' + '.npy')\n",
    "        except FileNotFoundError:\n",
    "            loaded_density = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "\n",
    "        Ne_save = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "        Ne_save = loaded_density + Ne_array\n",
    "        np.save(npy_files_path + 'density_geomagnetic' + '.npy', Ne_save)\n",
    "\n",
    "        try:\n",
    "            loaded_correlation_model = np.load(npy_files_path + 'correlation_model_geomagnetic' + '.npy')\n",
    "        except FileNotFoundError:\n",
    "            loaded_correlation_model = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "\n",
    "        corr_model_save = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "        corr_model_save = loaded_correlation_model + corr_model_array\n",
    "        np.save(npy_files_path + 'correlation_model_geomagnetic' + '.npy', corr_model_save)\n",
    "\n",
    "        try:\n",
    "            loaded_correlation_measure = np.load(npy_files_path + 'correlation_measure_geomagnetic' + '.npy')\n",
    "        except FileNotFoundError:\n",
    "            loaded_correlation_measure = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "\n",
    "        corr_measure_save = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "        corr_measure_save = loaded_correlation_measure + corr_measure_array\n",
    "        np.save(npy_files_path + 'correlation_measure_geomagnetic' + '.npy', corr_measure_save)\n",
    "\n",
    "        try:\n",
    "            loaded_frequency = np.load(npy_files_path + 'frequency_geomagnetic' + '.npy')\n",
    "        except FileNotFoundError:\n",
    "            loaded_frequency = np.ones(len(time_save)*len(np.unique(H_list)) + 1)\n",
    "\n",
    "        mask = np.array(Ne_array) != 0\n",
    "\n",
    "        freq_save = np.zeros(len(time_save)*len(np.unique(H_list)) + 1)\n",
    "        freq_save[1:][mask] = 1\n",
    "        freq_save += loaded_frequency\n",
    "        freq_save[0] += 1\n",
    "        np.save(npy_files_path + 'frequency_geomagnetic' + '.npy', freq_save)\n",
    "    elif folder[-4:] == '-SOL':\n",
    "        try:\n",
    "            loaded_density = np.load(npy_files_path + 'density_solar_proton' + '.npy')\n",
    "        except FileNotFoundError:\n",
    "            loaded_density = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "\n",
    "        Ne_save = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "        Ne_save = loaded_density + Ne_array\n",
    "        np.save(npy_files_path + 'density_solar_proton' + '.npy', Ne_save)\n",
    "\n",
    "        try:\n",
    "            loaded_correlation_model = np.load(npy_files_path + 'correlation_model_solar_proton' + '.npy')\n",
    "        except FileNotFoundError:\n",
    "            loaded_correlation_model = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "\n",
    "        corr_model_save = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "        corr_model_save = loaded_correlation_model + corr_model_array\n",
    "        np.save(npy_files_path + 'correlation_model_solar_proton' + '.npy', corr_model_save)\n",
    "\n",
    "        try:\n",
    "            loaded_correlation_measure = np.load(npy_files_path + 'correlation_measure_solar_proton' + '.npy')\n",
    "        except FileNotFoundError:\n",
    "            loaded_correlation_measure = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "\n",
    "        corr_measure_save = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "        corr_measure_save = loaded_correlation_measure + corr_measure_array\n",
    "        np.save(npy_files_path + 'correlation_measure_solar_proton' + '.npy', corr_measure_save)\n",
    "\n",
    "        try:\n",
    "            loaded_frequency = np.load(npy_files_path + 'frequency_solar_proton' + '.npy')\n",
    "        except FileNotFoundError:\n",
    "            loaded_frequency = np.ones(len(time_save)*len(np.unique(H_list)) + 1)\n",
    "\n",
    "        mask = np.array(Ne_array) != 0\n",
    "\n",
    "        freq_save = np.zeros(len(time_save)*len(np.unique(H_list)) + 1)\n",
    "        freq_save[1:][mask] = 1\n",
    "        freq_save += loaded_frequency\n",
    "        freq_save[0] += 1\n",
    "        np.save(npy_files_path + 'frequency_solar_proton' + '.npy', freq_save)\n",
    "    else:\n",
    "        try:\n",
    "            loaded_density = np.load(npy_files_path + 'density_other' + '.npy')\n",
    "        except FileNotFoundError:\n",
    "            loaded_density = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "\n",
    "        Ne_save = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "        Ne_save = loaded_density + Ne_array\n",
    "        np.save(npy_files_path + 'density_other' + '.npy', Ne_save)\n",
    "\n",
    "        try:\n",
    "            loaded_correlation_model = np.load(npy_files_path + 'correlation_model_other' + '.npy')\n",
    "        except FileNotFoundError:\n",
    "            loaded_correlation_model = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "\n",
    "        corr_model_save = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "        corr_model_save = loaded_correlation_model + corr_model_array\n",
    "        np.save(npy_files_path + 'correlation_model_other' + '.npy', corr_model_save)\n",
    "\n",
    "        try:\n",
    "            loaded_correlation_measure = np.load(npy_files_path + 'correlation_measure_other' + '.npy')\n",
    "        except FileNotFoundError:\n",
    "            loaded_correlation_measure = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "\n",
    "        corr_measure_save = np.zeros(len(time_save)*len(np.unique(H_list)))\n",
    "        corr_measure_save = loaded_correlation_measure + corr_measure_array\n",
    "        np.save(npy_files_path + 'correlation_measure_other' + '.npy', corr_measure_save)\n",
    "\n",
    "        try:\n",
    "            loaded_frequency = np.load(npy_files_path + 'frequency_other' + '.npy')\n",
    "        except FileNotFoundError:\n",
    "            loaded_frequency = np.ones(len(time_save)*len(np.unique(H_list)) + 1)\n",
    "\n",
    "        mask = np.array(Ne_array) != 0\n",
    "\n",
    "        freq_save = np.zeros(len(time_save)*len(np.unique(H_list)) + 1)\n",
    "        freq_save[1:][mask] = 1\n",
    "        freq_save += loaded_frequency\n",
    "        freq_save[0] += 1\n",
    "        np.save(npy_files_path + 'frequency_other' + '.npy', freq_save)\n",
    "\n",
    "    print('Folder: '+str(folder) + ', Global model correlation: ' + str(int(global_corr_model*100)/100) + ', Global measure correlation: ' + str(int(global_corr_measure*100)/100) + ', index: ' + str(index) + '/' + str(len(data_folders)))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import netCDF4\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions and variables\n",
    "k = 1.38*10**(-23) # J/K\n",
    "def Ne_convert(e: float,P: float,T: float) -> float:\n",
    "    return e*P/(k*T)\n",
    "\n",
    "def z(p):\n",
    "    return - 7 * np.log(p/1013.25)\n",
    "\n",
    "def format_time(hours_float):\n",
    "    hours = int(hours_float)\n",
    "    minutes_float = (hours_float - hours) * 60\n",
    "    minutes = int(minutes_float)\n",
    "    formatted_time = f'{hours:02}:{minutes:02}:00Z'\n",
    "    return formatted_time\n",
    "\n",
    "time_save = np.arange(0,24,0.5) \n",
    "time_bin = time_save[1]\n",
    "H_save = np.arange(90,130,10)\n",
    "h_bin = H_save[1]\n",
    "bins = len(time_save) * len(H_save) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278 folders found.\n",
      "1097 days founds.\n",
      "1097 days founds.\n"
     ]
    }
   ],
   "source": [
    "data_folder_path = '../../DataSorted/*'\n",
    "data_folders = glob(data_folder_path)\n",
    "data_folders = sorted(data_folders)\n",
    "print(len(data_folders), 'folders found.')\n",
    "\n",
    "dst_index_path = '../../DST_index/global_dst.csv'\n",
    "dst_index_file = pd.read_csv(dst_index_path)\n",
    "print(len(dst_index_file), 'days founds.')\n",
    "\n",
    "hp30_index_path = '../../hp30_index/global_hp30.json'\n",
    "with open(hp30_index_path, 'r') as file:\n",
    "    hp30_index_file = json.load(file)\n",
    "    hp30_date = np.array(hp30_index_file['datetime'])\n",
    "    hp30_index = np.array(hp30_index_file['Hp30'])\n",
    "print(int(len(hp30_index_file['datetime'])/48), 'days founds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8984ce7a39784240bf2e80661db6acf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=1, bar_style='info', description='Progress:', max=278)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Array for all values we want\n",
    "Ne_EXP_global = np.array([])\n",
    "dNe_EXP_global = np.array([])\n",
    "Ne_WACCM_global = np.array([])\n",
    "mag_EXP_global = np.array([])\n",
    "dmag_EXP_global = np.array([])\n",
    "mag_WACCM_global = np.array([])\n",
    "Date_Global = np.array([])\n",
    "Geo_Event = np.array([])\n",
    "Solar_Event = np.array([])\n",
    "Svalbard_Data = np.array([])\n",
    "Tromso_Data = np.array([])\n",
    "Height_Global = np.array([])\n",
    "Hours_Global = np.array([])\n",
    "dst_global = np.array([])\n",
    "ddst_global = np.array([])\n",
    "hp30_global = np.array([])\n",
    "dhp30_global = np.array([])\n",
    "\n",
    "folder_index = 1\n",
    "\n",
    "progress_bar = widgets.IntProgress(\n",
    "    value=folder_index,\n",
    "    min  = 0,\n",
    "    max  = len(data_folders),\n",
    "    description = 'Progress:',\n",
    "    bar_style   = 'info',\n",
    "    orientation = 'horizontal'\n",
    ")\n",
    "display(progress_bar)\n",
    "\n",
    "# Iterating over folders\n",
    "for folder in data_folders:\n",
    "    # Glob path for each files\n",
    "    EXP_path = folder + '/MAD*.hdf5'\n",
    "    WACCM_path = folder + '/*.nc'\n",
    "\n",
    "    WACCM_files = []\n",
    "\n",
    "    if len(glob(WACCM_path)) > 1:\n",
    "        for file in glob(WACCM_path):\n",
    "            WACCM_files.append(netCDF4.Dataset(file))\n",
    "    elif len(glob(WACCM_path)) == 1:\n",
    "        WACCM_files = [netCDF4.Dataset(glob(WACCM_path)[0])]\n",
    "    else:\n",
    "        WACCM_files = []\n",
    "        break\n",
    "\n",
    "    # Iterating over all experiment file\n",
    "    for file in glob(EXP_path): \n",
    "        EXP_file = h5py.File(file)\n",
    "        \n",
    "        data = EXP_file['Data']['Table Layout'][:] # Get data from the file\n",
    "        metadata = EXP_file['Metadata']['Data Parameters'][:] # Get data parameters from the file\n",
    "        parameters = [parameter[0] for parameter in metadata] # Get the name of each parameters\n",
    "\n",
    "        data = np.array([np.array(tuple.tolist()) for tuple in data])\n",
    "        dataframe = pd.DataFrame(data, columns=parameters)\n",
    "    \n",
    "        h_start = np.array(dataframe[b'GDALT']) # Start Altitude km\n",
    "        h_end = np.array(dataframe[b'RANGE']) # END Altitude km\n",
    "        Ne = np.array(dataframe[b'NE']) # Electron density m-3\n",
    "        dNe = np.array(dataframe[b'DNE']) # Electron density error m-3\n",
    "        Ti = np.array(dataframe[b\"TI\"]) # Ion temperature K\n",
    "        Tr = np.array(dataframe[b'TR']) # Electron to ion temperature ratio\n",
    "        hours = np.array(dataframe[b'HOUR']) # Hours\n",
    "        minutes = np.array(dataframe[b'MIN']) # Minutes\n",
    "\n",
    "        # Restrict experiment values to below 150 km\n",
    "        h_mask = h_end < 150\n",
    "        h_start = h_start[h_mask]\n",
    "        h_end = h_end[h_mask]\n",
    "        Ne = Ne[h_mask]\n",
    "        dNe = dNe[h_mask]\n",
    "        Ti = Ti[h_mask]\n",
    "        Tr = Tr[h_mask]\n",
    "        Te = Ti * Tr\n",
    "        hours = hours[h_mask]\n",
    "        minutes = minutes[h_mask]\n",
    "        time = hours + minutes/60\n",
    "\n",
    "        lat = WACCM_files[0]['instr_lat'][:] # Latitude of the instrument\n",
    "        lon = WACCM_files[0]['instr_lon'][:] # Longitude of the instrument\n",
    "        num = WACCM_files[0]['instr_num'][:] # Numerical identifier of the instrument\n",
    "        date = WACCM_files[0]['obs_date'][:] # Observation date\n",
    "        time_WACCM = WACCM_files[0]['obs_time'][:] # Observation time\n",
    "        lev = WACCM_files[0]['lev'][:] # 88 levels\n",
    "        e = WACCM_files[0]['e'][:] # Mixing ratio\n",
    "        T = WACCM_files[0]['T'] [:]# Temperature\n",
    "\n",
    "        for WACCM_file in WACCM_files[1:]:\n",
    "            temp_lat = WACCM_file['instr_lat'][:] # Latitude of the instrument\n",
    "            temp_lon = WACCM_file['instr_lon'][:] # Longitude of the instrument\n",
    "            temp_num = WACCM_file['instr_num'][:] # Numerical identifier of the instrument\n",
    "            temp_date = WACCM_file['obs_date'][:] # Observation date\n",
    "            temp_time = WACCM_file['obs_time'][:] # Observation time\n",
    "            temp_e = WACCM_file['e'][:] # Mixing ratio \n",
    "            temp_T = WACCM_file['T'][:] # Temperature\n",
    "\n",
    "            # Concatenate all model values into their unique array\n",
    "            lat = np.concatenate((lat, temp_lat))\n",
    "            lon = np.concatenate((lon, temp_lon))\n",
    "            num = np.concatenate((num, temp_num))\n",
    "            date = np.concatenate((date, temp_date))\n",
    "            time_WACCM = np.concatenate((time_WACCM, temp_time))\n",
    "            e = np.concatenate((e, temp_e))\n",
    "            T = np.concatenate((T, temp_T))\n",
    "        \n",
    "        # Date restriction\n",
    "        EXP_date = int(dataframe[b'YEAR'][0]*10000 + dataframe[b'MONTH'][0]*100 + dataframe[b'DAY'][0])\n",
    "        date_mask = date == EXP_date\n",
    "        lat = lat[date_mask]\n",
    "        lon = lon[date_mask]\n",
    "        time_WACCM = time_WACCM[date_mask]\n",
    "        e = e[date_mask]\n",
    "        T = T[date_mask]\n",
    "\n",
    "        # Coordinate restrictions for Tromsø and Svalbard\n",
    "        mask_tromso = (lat > 69.5) & (lat < 69.7)\n",
    "        mask_svalbard = (lat > 78.8) & (lat < 79.0)\n",
    "\n",
    "        if 'uhf' in file: # Check if this is a Tromsø experiment\n",
    "            mask_location = mask_tromso\n",
    "            Tromso_Data = np.concatenate((Tromso_Data, np.repeat(True, bins))) # See description.md for explanation of this part\n",
    "            Svalbard_Data = np.concatenate((Svalbard_Data, np.repeat(False, bins))) # See description.md for explanation of this part\n",
    "        elif '42m' in file: # Check if this is a Svalbard experiment\n",
    "            mask_location = mask_svalbard\n",
    "            Tromso_Data = np.concatenate((Tromso_Data, np.repeat(False, bins))) # See description.md for explanation of this part\n",
    "            Svalbard_Data = np.concatenate((Svalbard_Data, np.repeat(True, bins))) # See description.md for explanation of this part\n",
    "\n",
    "        # Pressure restriction for model value, 0.01 approx 80 km\n",
    "        lev_mask = lev < 0.01\n",
    "        P = lev[lev_mask]\n",
    "        H = z(P)\n",
    "        NeWACCM = [] # Be careful this is not density but mixing ratio\n",
    "        for array in e[mask_location]:\n",
    "            NeWACCM.append(array[lev_mask])\n",
    "        NeWACCM = np.array(NeWACCM)\n",
    "\n",
    "        hours = time_WACCM[mask_location]/3600\n",
    "        T = T[mask_location]\n",
    "\n",
    "        # Split folder path to get specifif event \n",
    "        date = folder.split('/')[-1]\n",
    "\n",
    "        if 'GEO' in date and 'SOL' in date: # Check if it's both\n",
    "            date = date.replace('-GEO', '')\n",
    "            date = date.replace('-SOL', '')\n",
    "            Geo_Event = np.concatenate((Geo_Event, np.repeat(True, bins))) # See description.md for explanation of this part\n",
    "            Solar_Event = np.concatenate((Solar_Event, np.repeat(True, bins))) # See description.md for explanation of this part\n",
    "        elif 'GEO' in date and 'SOL' not in date: # Check if it's Geomagnetic event\n",
    "            date = date.replace('-GEO', '')\n",
    "            Geo_Event = np.concatenate((Geo_Event, np.repeat(True, bins))) # See description.md for explanation of this part\n",
    "            Solar_Event = np.concatenate((Solar_Event, np.repeat(False, bins))) # See description.md for explanation of this part\n",
    "        elif 'GEO' not in date and 'SOL' in date: # Check if it's Solar event\n",
    "            date = date.replace('-SOL', '')\n",
    "            Geo_Event = np.concatenate((Geo_Event, np.repeat(False, bins))) # See description.md for explanation of this part\n",
    "            Solar_Event = np.concatenate((Solar_Event, np.repeat(True, bins))) # See description.md for explanation of this part\n",
    "        else:\n",
    "            Geo_Event = np.concatenate((Geo_Event, np.repeat(False, bins))) # See description.md for explanation of this part\n",
    "            Solar_Event = np.concatenate((Solar_Event, np.repeat(False, bins))) # See description.md for explanation of this part\n",
    "\n",
    "        # Create list for ease of use (append)\n",
    "        Ne_EXP_list = []\n",
    "        dNe_EXP_list = []\n",
    "        Ne_WACCM_list = []\n",
    "        dst_list = []\n",
    "        ddst_list = []\n",
    "        hp30_list = []\n",
    "        dhp30_list = []\n",
    "\n",
    "        # Mask based on the date for the DST index \n",
    "        dst_mask = np.array(dst_index_file['DATE'] == date) \n",
    "        # Shift the DST mask to get the next day after the current date\n",
    "        dst_shifted = np.roll(dst_mask,1) \n",
    "        \n",
    "        # Iterating over all altitude slot \n",
    "        for height_slot in H_save:\n",
    "            h_start_mask = (h_start - height_slot <= h_bin) & (h_start - height_slot > 0) # Check if start altitude of the measurements if in the slot (Experiment)\n",
    "            h_end_mask = (h_end - height_slot <= h_bin) & (h_end - height_slot > 0) # Check if end altitude of the measurements if in the slot (Experiment)\n",
    "            h_mask_EXP = h_start_mask + h_end_mask # Combine both experiment mask\n",
    "            h_mask_WACCM = (H - height_slot <= h_bin) & (H - height_slot > 0) # Check if model altitude is in the slot\n",
    "            # Iterating over all time slot \n",
    "            for time_slot in time_save:\n",
    "                t_mask_EXP = (time[h_mask_EXP] - time_slot <= time_bin) & (time[h_mask_EXP] - time_slot > 0) # Check if the start time of the experiment is in slot(Experiment)\n",
    "                t_mask_WACCM = (hours - time_slot <= 0.5) & (hours - time_slot > 0) # Check if the model time is in the slot\n",
    "                if sum(t_mask_EXP) == 0: # Check if there is no experiment measure in this bin (time slot x altitude slot)\n",
    "                    # Add 0 for each value\n",
    "                    Ne_EXP_list.append(0)\n",
    "                    dNe_EXP_list.append(0)\n",
    "                    Ne_WACCM_list.append(0)\n",
    "                    dst_list.append(0)\n",
    "                    ddst_list.append(0)\n",
    "                    hp30_list.append(0)\n",
    "                    dhp30_list.append(0)\n",
    "                elif sum(t_mask_WACCM) == 0:# Check if there is no model estimation in this bin (time slot x altitude slot)\n",
    "                    # Add 0 for each value\n",
    "                    Ne_EXP_list.append(0)\n",
    "                    dNe_EXP_list.append(0)\n",
    "                    Ne_WACCM_list.append(0)\n",
    "                    dst_list.append(0)\n",
    "                    ddst_list.append(0)\n",
    "                    hp30_list.append(0)\n",
    "                    dhp30_list.append(0)\n",
    "                else:\n",
    "                    Ne2_EXP = np.mean(Ne[h_mask_EXP][t_mask_EXP]) # Get the mean value of the experiment measures in this bin\n",
    "                    Ne_EXP_list.append(Ne2_EXP) # Add this mean to the list\n",
    "                    dNe_EXP = np.sqrt(np.sum(dNe[h_mask_EXP][t_mask_EXP]**2))/len(dNe[h_mask_EXP][t_mask_EXP]) # Get the squared root of the sum of squared error (see description.md for further explanation)\n",
    "                    dNe_EXP_list.append(dNe_EXP) # Add this value to the list\n",
    "\n",
    "                    Ne2_WACCM_array = np.array([]) #\n",
    "                    index = 0\n",
    "                    for index in range(len(NeWACCM[t_mask_WACCM])): # Iterating over all mixing ratios arrays in the array\n",
    "                        Ne_array = NeWACCM[t_mask_WACCM][index][h_mask_WACCM] # Get the current mixing ration array\n",
    "                        T_array = T[t_mask_WACCM][index][lev_mask][h_mask_WACCM] # Get the current temperature array\n",
    "                        # Convert mixing ratios to density and add them to the global array (see description.md for further explanation)\n",
    "                        Ne2_WACCM_array = np.concatenate((Ne2_WACCM_array, Ne_convert(Ne_array,P[h_mask_WACCM]*100,T_array))) \n",
    "                    Ne2 =  np.mean(Ne2_WACCM_array) # Mean the densities\n",
    "                    Ne_WACCM_list.append(Ne2) # Add this mean to the list\n",
    "\n",
    "                    int_hour_str = str(int(time_slot) + 1) # As DST values are shifted we need to shift or time slot by one hour\n",
    "                    next_int_hour_str = str(int(time_slot + time_bin) + 1) # Get next hour we will use\n",
    "                    dst = dst_index_file[int_hour_str][dst_mask].values[0] # Get current DST value\n",
    "\n",
    "                    # Further explanation of this part in description.md\n",
    "                    if (time_bin == 1 or int_hour_str == next_int_hour_str) and int_hour_str != '24':\n",
    "                        dst_list.append(dst) # Add the DST value\n",
    "                        next_dst = dst_index_file[next_int_hour_str][dst_mask].values[0] # Get the next DST value\n",
    "                        ddst_list.append((next_dst - dst)/time_bin) # Add the gradient\n",
    "                    elif int_hour_str != next_int_hour_str and int_hour_str != '24': # Check is the two hour are the same and the first is not 24\n",
    "                        next_dst = dst_index_file[next_int_hour_str][dst_mask].values[0] # Get next DST value\n",
    "                        dst_list.append((dst + next_dst)/2) # Add the mean of the two DST value\n",
    "                        ddst_list.append((next_dst - dst)/(2*time_bin)) # Add the gradient\n",
    "                    else: # this happens only when HH:mm = 24:00\n",
    "                        dst_list.append(dst) # add the DST value\n",
    "                        next_dst = dst_index_file['1'][dst_shifted].values[0] # Get the next DST value\n",
    "                        ddst_list.append((next_dst - dst)/time_bin) # Add the gradient\n",
    "\n",
    "                    # Date mask for Hp30 index , for which time slot must be formatted\n",
    "                    hp30_mask = hp30_date == f'{date}T{format_time(time_slot)}'\n",
    "                    hp30_shifted = np.roll(hp30_mask, 1) # Shift the mask for the gradient\n",
    "                    hp30 = hp30_index[hp30_mask][0] # Get current Hp30 value\n",
    "                    next_hp30 = hp30_index[hp30_shifted][0] # Get next Hp30 value\n",
    "                    dhp30 = (next_hp30 - hp30)/time_bin # Compute the gradient\n",
    "                    hp30_list.append(hp30) # Add the value\n",
    "                    dhp30_list.append(int(dhp30*100)/100) # Add the gradient (with 3 significant digits)\n",
    "                    \n",
    "            Hours_Global = np.concatenate((Hours_Global, time_save)) # See description.md for explanation of this part\n",
    "            Height_Global = np.concatenate((Height_Global, np.repeat(height_slot, len(time_save)))) # See description.md for explanation of this part\n",
    "\n",
    "        # Convert all list to array, and fix their types if needed\n",
    "        Ne_EXP = np.array(Ne_EXP_list).astype(int)\n",
    "        dNe_EXP = np.array(dNe_EXP_list).astype(int)\n",
    "        Ne_WACCM = np.array(Ne_WACCM_list).astype(int)\n",
    "        dst_array = np.array(dst_list)\n",
    "        ddst_array = np.array(ddst_list)\n",
    "        hp30_array = np.array(hp30_list)\n",
    "        dhp30_array = np.array(dhp30_list)\n",
    "\n",
    "        # Extract nan value that can occurs in the experiment\n",
    "        nan_mask = np.isnan(Ne_EXP)\n",
    "        Ne_EXP[nan_mask] = 0\n",
    "        Ne_WACCM[nan_mask] = 0\n",
    "\n",
    "        # Create empty magnitude array\n",
    "        mag_EXP = np.zeros((len(H_save) * len(time_save)))\n",
    "        dmag_EXP = np.zeros((len(H_save) * len(time_save)))\n",
    "        mag_WACCM = np.zeros((len(H_save) * len(time_save)))\n",
    "        \n",
    "        # Take care of the 0 values in the array\n",
    "        mask_zero = Ne_EXP != 0\n",
    "        # Compute their magnitude\n",
    "        mag_EXP[mask_zero] = np.log10(Ne_EXP[mask_zero])\n",
    "        dmag_EXP[mask_zero] = np.log10(dNe_EXP[mask_zero])\n",
    "        mag_WACCM[mask_zero] = np.log10(Ne_WACCM[mask_zero])\n",
    "\n",
    "        # Correct the values with 3 significant digits\n",
    "        mag_EXP = (mag_EXP*100).astype(int)/100\n",
    "        dmag_EXP = (dmag_EXP*100).astype(int)/100\n",
    "        mag_WACCM = (mag_WACCM*100).astype(int)/100\n",
    "\n",
    "        # Concatenate all current arrays with their global arrays\n",
    "        Ne_EXP_global = np.concatenate((Ne_EXP_global, Ne_EXP))\n",
    "        dNe_EXP_global = np.concatenate((dNe_EXP_global, dNe_EXP))\n",
    "        Ne_WACCM_global = np.concatenate((Ne_WACCM_global, Ne_WACCM))\n",
    "        \n",
    "        mag_EXP_global = np.concatenate((mag_EXP_global, mag_EXP))\n",
    "        dmag_EXP_global = np.concatenate((dmag_EXP_global, dmag_EXP))\n",
    "        mag_WACCM_global = np.concatenate((mag_WACCM_global, mag_WACCM))\n",
    "\n",
    "        dst_global = np.concatenate((dst_global, dst_array))\n",
    "        ddst_global = np.concatenate((ddst_global, ddst_array))\n",
    "        hp30_global = np.concatenate((hp30_global, hp30_array))\n",
    "        dhp30_global = np.concatenate((dhp30_global, dhp30_array))\n",
    "\n",
    "        Date_Global = np.concatenate((Date_Global, np.repeat(date, bins)))\n",
    "    \n",
    "    folder_index += 1\n",
    "    progress_bar.value = folder_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'Date' : Date_Global,\n",
    "             'Hours' : Hours_Global,\n",
    "             'Height' : Height_Global.astype(int),\n",
    "             'Svalbard' : Svalbard_Data.astype(int),\n",
    "             'Tromso' : Tromso_Data.astype(int),\n",
    "             'Geomagnetic Event' : Geo_Event.astype(int),\n",
    "             'Solar Proton Event' : Solar_Event.astype(int),\n",
    "             'EXP Density' : Ne_EXP_global.astype(int),\n",
    "             'EXP Density Error' : dNe_EXP_global.astype(int),\n",
    "             'WACCM Density' : Ne_WACCM_global.astype(int),\n",
    "             'EXP Magnitude' : mag_EXP_global,\n",
    "             'EXP Magnitude Error' : dmag_EXP_global, \n",
    "             'WACCM Magnitude' : mag_WACCM_global,\n",
    "             'DST Index' : dst_global,\n",
    "             'DST Index Gradient' : ddst_global,\n",
    "             'Hp30 Index' : hp30_global,\n",
    "             'Hp30 Index Gradient' : dhp30_global,\n",
    "            }\n",
    "\n",
    "data_df = pd.DataFrame(data_dict)\n",
    "file = f'global_data_{len(H_save)}_{len(time_save)}'\n",
    "data_df.to_csv('../../Results/' + file + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
